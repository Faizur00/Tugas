





import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
from sklearn.metrics import classification_report
import joblib





# Gunakan dataset hasil clustering yang memiliki fitur Target
# Silakan gunakan dataset data_clustering jika tidak menerapkan Interpretasi Hasil Clustering [Advanced]
# Silakan gunakan dataset data_clustering_inverse jika menerapkan Interpretasi Hasil Clustering [Advanced]

### MULAI CODE ###

df = pd.read_csv("data_clustering_inverse.csv")

### SELESAI CODE ###


# Tampilkan 5 baris pertama dengan function head

### MULAI CODE ###

df.head()

### SELESAI CODE ###





### MULAI CODE OPSIONAL ###

categorical_cols = list(df.select_dtypes(include=['object']).columns)

# Gunakan 'pd.get_dummies' untuk melakukan OneHotEncoding
df_encoded = pd.get_dummies(
    df,
    columns = categorical_cols,
    drop_first = True
)

# Tampilkan 5 baris pertama untuk memverifikasi hasilnya
df_encoded.head()

### SELESEI CODE OPSIONAL ###





# Menggunakan train_test_split() untuk melakukan pembagian dataset.

### MULAI CODE ###

# Buat 'X' dengan menghapus 'Target' dari 'df_encoded' dan gunakan 'axis=1' untuk menandakan drop kolom.
X = df_encoded.drop('Target', axis=1)

# Buat 'y' dengan HANYA memilih kolom 'Target'.
y = df_encoded['Target']

# Panggil fungsi untuk membagi data.
#  - Gunakan 'stratify=y' agar proporsi kelas di train/test set sama.
X_train, X_test, y_train, y_test = train_test_split(
    X,
    y,
    test_size = 0.2,
    random_state = 42,
    stratify = y
)

### SELESAI CODE ###

print("Jumlah data total: ",len(X))
print("Jumlah data latih: ",len(X_train))
print("Jumlah data test: ",len(X_test))





# Buatlah model klasifikasi menggunakan Decision Tree

### MULAI CODE ###

# 1. Buat (instantiate) objek model Decision Tree
#    Gunakan 'random_state=42' agar hasilnya konsisten
decision_tree_model = DecisionTreeClassifier(random_state=42)

# 2. Latih (fit) model dengan data training (X_train dan y_train)
decision_tree_model.fit(X_train, y_train)

### SELESAI CODE ###


# Menyimpan Model

### MULAI CODE ###

joblib.dump(decision_tree_model, 'decision_tree_model.h5')

### SELESAI CODE ###








# Melatih model menggunakan algoritma klasifikasi scikit-learn selain Decision Tree. (Contoh: RandomForestClassifier)

### MULAI CODE ###

# Buat (instantiate) objek model baru
new_model = RandomForestClassifier(n_estimators=100,criterion='entropy',max_depth=10)

# Latih (fit) model dengan data training (X_train dan y_train)
new_model.fit(X_train, y_train)

### SELESAI CODE ###


# Menampilkan hasil evaluasi akurasi, presisi, recall, dan F1-Score pada seluruh algoritma yang sudah dibuat.

### MULAI CODE ###

# Buat prediksi pada data 'X_test' menggunakan kedua model
y_pred_dt = decision_tree_model.predict(X_test)
y_pred_new = new_model.predict(X_test)

# Tampilkan classification_report untuk Decision Tree
print("Decision Tree Performance")
print(classification_report(y_test,y_pred_dt))

print("="*50)

# Tampilkan classification_report untuk New Model
print("New Model Performance")
print(classification_report(y_test, y_pred_new))

### SELESAI CODE ###


# Menyimpan Model Selain Decision Tree
# Model ini bisa lebih dari satu

### MULAI CODE ###

joblib.dump(new_model, 'explore_RandomForest_classification.h5')

### SELESAI CODE ###





# Lakukan Hyperparameter Tuning dan Latih ulang.
# Lakukan dalam satu cell ini saja.

### MULAI CODE ###

# Tentukan Hyperparameter yang akan di-tuning
params = {
    'n_estimators': (50, 100, 500),
    'max_depth': (5, 10, 50),
    'criterion': ['gini', 'entropy']
}

# Buat (instantiate) objek dari algoritma tuning
#  - 'estimator': Model yang akan di-tuning
#  - 'params': Hyperparameter yang sudah kita tentukan
new_model_tuned = GridSearchCV(
    estimator = RandomForestClassifier(random_state=42),
    param_grid = params,
    cv = 5,
    scoring = 'accuracy'
)

# Latih objek model dengan data training (X_train dan y_train)
new_model_tuned.fit(X_train, y_train)

### SELESAI CODE ###


# Menampilkan hasil evaluasi akurasi, presisi, recall, dan F1-Score pada algoritma yang sudah dituning.

### MULAI CODE ###

# Buat prediksi pada 'X_test' Gunakan model yang sudah di-tuning
y_pred_tuning = new_model_tuned.predict(X_test)

# Tampilkan classification_report untuk model yang sudah di-tuning
print("Tuned Model Performance")
print(classification_report(y_test, y_pred_tuning))

### SELESAI CODE ###


# Menyimpan Model hasil tuning

### MULAI CODE

joblib.dump(new_model_tuned, 'tuning_classification.h5')

### SELESAI CODE ###



